Дисперсия суммы двух случайных величин равна
\begin{equation*}
    \D (\xi + \eta) = \D \xi + \D \eta + 2 \left(\E(\xi \eta) - \E (\xi) \E (\eta)\right).
\end{equation*}
Величина $\E (\xi \eta) - \E \xi \E \eta = 0$, если $\xi$ и $\eta$ независимы, но это верно только в одну сторону, поэтому эту величину используют как <<индикатор наличия зависимости>> между двумя случайными величинами. 

\begin{to_def}
    \textit{Ковариацией} $\cov(\xi, \eta)$ случайных величин $\xi$ и $\eta$ называется число
    \begin{equation}
        \cov (\xi, \eta) = \E \big[(\xi-\E \xi)(\eta - \E \eta)\big].
    \end{equation}
\end{to_def} 

\noindent
Для ковариации справедливы следующие равенства:
\begin{equation*}
    \cov(\xi ,\eta) = \E (\xi \eta) - \E (\xi) \E (\eta);
    \hspace{5 mm}
    \cov (\xi, \xi) = \D (\xi);
    \hspace{5 mm}   
    \cov(\xi, \eta) = \cov(\eta, \xi);
    \hspace{5 mm}
    \cov (c \xi, \eta) = c \, \cov (\xi, \eta).
\end{equation*}

\begin{to_lem}
    Дисперсия суммы нескольких случайных величин вычисляется по формуле:
    \begin{equation}
        \D (\xi_1 + \ldots + \xi_n) = 
        \sum_{i=1}^{n} \D (\xi_i) + \sum_{i \neq j} \cov (\xi_i, \xi_j) 
        =
        \sum_{i, j} \cov(\xi_i, \xi_j).
    \end{equation}
\end{to_lem}

Если ковариация $\cov (\xi, \eta) \neq 0$, то $\xi$ и $\eta$ зависимы. Найти совместное распределение бывает сложнее, чем посчитать $\E (\xi \eta)$, поэтому, если повезет, и $\E (\xi \eta) \neq \E (\xi) \E (\eta)$, то, не находя совместное распределение, мы обнаружим зависимость $\xi$ и $\eta$, не находя их совсметного распределения.
\texttt{Это очень хорошо.} 

Однако есть проблема -- ковариация не безразмерно, поэтому большие значения ковариции не говорят о более сильной зависимости. Хотелось бы как-то отнормировать $\cov (\xi, \eta)$, получив <<безразмерную>> величину. Так мы приходим к коэффициенту корреляции. 

